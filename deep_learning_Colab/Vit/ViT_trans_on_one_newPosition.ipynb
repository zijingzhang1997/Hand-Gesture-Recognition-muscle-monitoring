{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ViT_trans_on_one_newPosition.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"16RkPv7Q9plSR7wXdAgYyUOhVP88pm8xj","authorship_tag":"ABX9TyOgxnC2WZCW0v2F7vcUBMuD"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"ZII5pk69M1cG","executionInfo":{"status":"ok","timestamp":1646684297779,"user_tz":300,"elapsed":6202,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"source":["import os\n","import numpy as np\n","import matplotlib\n","import torch\n","# !pip install mat73\n","# import mat73\n","import matplotlib.pyplot as plt\n","import csv\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, random_split,TensorDataset\n","from torchvision import transforms, utils\n","import time\n","import pandas as pd\n","import scipy.io\n","import sklearn.metrics\n","import seaborn as sns\n","import random\n","from sklearn.model_selection import train_test_split\n","from torchvision.transforms import ToTensor\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score\n","random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","np.random.seed(1)\n","\n","from scipy import signal\n","\n","from sklearn.metrics import confusion_matrix\n","\n","import seaborn as sn\n","import pandas as pd\n","\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.model_selection import LeaveOneGroupOut\n","\n","\n","\n","\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from math import sqrt\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","!pip install einops\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","\n","# helpers\n","\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","# classes\n","\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class LSA(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        self.heads = heads\n","        self.temperature = nn.Parameter(torch.log(torch.tensor(dim_head ** -0.5)))\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.temperature.exp()\n","\n","        mask = torch.eye(dots.shape[-1], device = dots.device, dtype = torch.bool)\n","        mask_value = -torch.finfo(dots.dtype).max\n","        dots = dots.masked_fill(mask, mask_value)\n","\n","        attn = self.attend(dots)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n","        super().__init__()\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, LSA(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n","            ]))\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","        return x\n","\n","class SPT(nn.Module):\n","    def __init__(self, *, dim, patch_size, channels = 3):\n","        super().__init__()\n","        patch_dim = patch_size * patch_size * 5 * channels\n","\n","        self.to_patch_tokens = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n","            nn.LayerNorm(patch_dim),\n","            nn.Linear(patch_dim, dim)\n","        )\n","\n","    def forward(self, x):\n","        shifts = ((1, -1, 0, 0), (-1, 1, 0, 0), (0, 0, 1, -1), (0, 0, -1, 1))\n","        shifted_x = list(map(lambda shift: F.pad(x, shift), shifts))\n","        x_with_shifts = torch.cat((x, *shifted_x), dim = 1)\n","        return self.to_patch_tokens(x_with_shifts)\n","\n","class ViT(nn.Module):\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = SPT(dim = dim, patch_size = patch_size, channels = channels)\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, img):\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x)\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WbbJyKP4Y8zU","executionInfo":{"status":"ok","timestamp":1646684301214,"user_tz":300,"elapsed":3437,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}},"outputId":"0428bce3-aa8a-4381-a9da-5bb132e97e93"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting einops\n","  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n","Installing collected packages: einops\n","Successfully installed einops-0.4.1\n"]}]},{"cell_type":"code","source":["def Load_TransModel(FeatType,person,opt):\n","\n","\n","  dataPath=\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"\n","  FeatName=['stft','stft2','cwt','cwt2','cwt3'] \n","  \n","  PATH=dataPath+\"/model_all_vit/\"+opt['modelVer']+\"/\"+FeatName[FeatType]+\"_ex_\"+str(person)+\".pt\"\n","  model_trans = ViT(\n","        image_size =opt['image_size'],\n","        patch_size = opt['patch_size'],\n","        num_classes =num_class,\n","        dim = par_vit['dim'],\n","        depth = par_vit['depth'],\n","        heads = par_vit['heads'],\n","        mlp_dim = par_vit['mlp_dim'],\n","        dropout = par_vit['dropout'],\n","        emb_dropout = par_vit['emb_dropout'],\n","        channels = in_ch\n","        ).cuda()\n","  model_trans.load_state_dict(torch.load(PATH))\n","  model_trans.eval()\n","\n","  # for param in model_trans.parameters():\n","  #     param.requires_grad = False\n","\n","  # model_trans.fc1 = nn.Linear(model_trans.fc1.in_features, model_trans.fc2.in_features)\n","  # model_trans.fc2 = nn.Linear(model_trans.fc2.in_features, num_class)\n","  return model_trans\n","\n","\n","\n"],"metadata":{"id":"VgrJAtXbYyoc","executionInfo":{"status":"ok","timestamp":1646684301214,"user_tz":300,"elapsed":4,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"ziBgA5vmETTi","executionInfo":{"status":"ok","timestamp":1646684301525,"user_tz":300,"elapsed":315,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"source":["in_ch=48\n","num_class=23\n","self_channel=[0,1,10,11,20,21,30,31]\n","par_vit1={'dim':512,'depth':6,'heads':16,'mlp_dim':32,'dropout':0.1,'emb_dropout':0.1};\n","par_vit2={'dim':1024,'depth':6,'heads':16,'mlp_dim':32,'dropout':0.1,'emb_dropout':0.1};\n","par_vit=par_vit1\n","parameter_vit=np.array(list(par_vit.items()));\n","\n","def test_trans(X_all,y_all,opt,k_split,n_sel,trans_net):\n","  import torch\n","  torch.cuda.empty_cache()\n","\n","  if __name__ == '__main__':\n","      \n","      transform = ToTensor()\n","      batchsize_train = 16\n","\n","      folds=RepeatedStratifiedKFold(n_splits=k_split, n_repeats=1,random_state=100).split(X_all,y_all)\n","\n","      test_ind_all=[]\n","      train_ind_all=[]\n","      for train_index, test_index in folds:\n","        test_ind_all.append(test_index)\n","        train_ind_all.append(train_index)\n","      \n","\n","      # train_ind=train_ind_all[n_sel]\n","      # test_ind=test_ind_all[n_sel]\n","\n","      # swap train & test index \n","      # select one fold to be trained by n_sel\n","      train_ind=test_ind_all[n_sel]\n","      test_ind=train_ind_all[n_sel]\n","\n","\n","      X_train=X_all[train_ind] \n","      X_test=X_all[test_ind]\n","      y_train=y_all[train_ind] \n","      y_test=y_all[test_ind]\n","\n","      train_loader = DataLoader(TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train)), batch_size=batchsize_train,shuffle=True)\n","      batchsize_test = 16\n","      test_loader = DataLoader(TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test)), batch_size=batchsize_test, shuffle=False)\n","\n","\n","      # (unique, counts) = np.unique(perNum_all_per[ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","\n","      # (unique, counts) = np.unique(label_all_per[ind][train_ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","      # (unique, counts) = np.unique(label_all_per[ind][test_ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","\n","      #hyperparameter definition   \n","      momentum = 0.1\n","      random_seed=1\n","      torch.backends.cudnn.enabled = False\n","      torch.manual_seed(random_seed)     #设定随机数种子为固定值\n","      \n","      train_loss_epoch = []\n","      test_acc_epoch =[]\n","      total_acc_epoch = []\n","      #epoch_range = np.arange(25,225,25)\n","      epoch_range = np.array([2])\n","\n","   \n","      if  opt['trans']==0:\n","        network = ViT(\n","        image_size = opt['image_size'],\n","        patch_size = opt['patch_size'],\n","        num_classes =num_class,\n","        dim = par_vit['dim'],\n","        depth = par_vit['depth'],\n","        heads = par_vit['heads'],\n","        mlp_dim = par_vit['mlp_dim'],\n","        dropout = par_vit['dropout'],\n","        emb_dropout = par_vit['emb_dropout'],\n","        channels = in_ch\n","        ).cuda()\n","      if opt['trans']==1:\n","        network =trans_net.cuda()\n","      #training\n","      learning_rate=opt['learning rate']\n","      optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n","      #optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n","      \n","\n","      #network.train()\n","      Training_Loss = []\n","      Test_Loss = []\n","      start_time = time.time()\n","      criterion = nn.CrossEntropyLoss()\n","      #criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 3]).cuda())\n","      for epoch in range(opt['n_epoch']):   # loop over the dataset multiple times\n","          train_loss = 0\n","          for X, Y in train_loader:\n","              # X = X.view(-1,1,X.shape[2],X.shape[3]).cuda()\n","              X = X.float().cuda()  \n","              Y = Y.long().view(-1, ).cuda() \n","              current_batchsize = X.shape[0]\n","              optimizer.zero_grad()\n","              output = network(X)\n","              loss = criterion(output,Y)\n","              train_loss = train_loss + loss.item()\n","              loss.backward()                     #calculate the gradient decent\n","              optimizer.step()                    #update the weight\n","              \n","            \n","          test_loss = 0\n","          correct = 0\n","          total = 0\n","          test_y= []\n","          test_y_p = []\n","     \n","          with torch.no_grad():        \n","              # X = X.view(-1,X.shape[1],X.shape[2])\n","              # X = X.float()         \n","              for X, Y in test_loader:\n","                  X = torch.Tensor(X).cuda()\n","                  Y = torch.Tensor(Y).long().view(-1, ).cuda()\n","                  images, labels = X, Y\n","                  # calculate outputs by running images through the network\n","                  outputs = network(images)\n","                  loss = criterion(outputs,Y)\n","                  test_loss = test_loss + loss.item()\n","\n","                  # the class with the highest energy is what we choose as prediction\n","                  _, predicted = torch.max(outputs.data, 1)\n","                  total += labels.size(0)\n","                  correct += (predicted == labels).sum().item()\n","                  \n","                  for i in range(len(labels)):\n","                    test_y.append(labels[i])\n","                    test_y_p.append(predicted[i])\n","          \n","          #print('Accuracy of test cases: %d %%' % (100 * correct / total))\n","  \n","\n","          Training_Loss.append(train_loss/len(train_loader.dataset))\n","          Test_Loss.append(test_loss/len(test_loader.dataset))\n","          # if epoch%2==0:\n","          #     print(train_loss/len(train_loader.dataset))\n","          #     print(test_loss/len(test_loader.dataset))\n","        \n","      \n","      # train_loss_epoch.append(Training_Loss[-1])\n","      # training_time=time.time()-start_time\n","      #print('total training time is',training_time)\n","      \n","      # plt.figure()\n","      # plt.plot(Training_Loss)\n","      # plt.title(\"training loss\")\n","      # plt.xlabel(\"epoch\")\n","      # plt.show()\n","\n","      # plt.figure()\n","      # plt.plot(Test_Loss)\n","      # plt.title(\"test loss\")\n","      # plt.xlabel(\"epoch\")\n","      # plt.plot(Training_Loss)\n","      # plt.show()\n","\n","  test_y_p=torch.FloatTensor(test_y_p)\n","  test_y=torch.FloatTensor(test_y)\n","  test_y_p=np.array(test_y_p.cpu())\n","  test_y=np.array(test_y.cpu())\n","  test_y2=np.stack((test_y, test_y_p))\n","  \n","  train_ind_inAll=train_ind\n","  test_ind_inAll=test_ind\n","\n","  trn_tst_ind=[train_ind_inAll,test_ind_inAll]\n","\n","  cm=confusion_matrix(test_y, test_y_p)\n","  acc=accuracy_score(test_y, test_y_p)\n","  print(cm,acc)\n","  return cm,acc,test_y2,train_ind_inAll,test_ind_inAll\n","\n","\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","source":["mVer='v1_per8'\n","opt1={'image_size':56,'patch_size':7,'modelVer':mVer}\n","opt2={'image_size':40,'patch_size':5,'modelVer':mVer}\n","opt3={'image_size':125,'patch_size':5,'modelVer':mVer}\n","## for testing kfold CV transfer option\n","n1=40\n","lr1=2e-4\n","# was lr1=1e-5 for multiple participant 8per dataset \n","opt1_t1={'image_size':56,'patch_size':7,'trans':1,'learning rate':lr1,'n_epoch':n1}\n","opt2_t1={'image_size':40,'patch_size':5,'trans':1,'learning rate':lr1,'n_epoch':n1}\n","opt3_t1={'image_size':125,'patch_size':5,'trans':1,'learning rate':lr1,'n_epoch':n1}\n","## for testing kfold CV not transfer option\n","n2=20\n","opt1_t0={'image_size':56,'patch_size':7,'trans':0,'learning rate':1e-4,'n_epoch':n2}\n","opt2_t0={'image_size':40,'patch_size':5,'trans':0,'learning rate':1e-4,'n_epoch':n2}\n","opt3_t0={'image_size':125,'patch_size':5,'trans':0,'learning rate':1e-4,'n_epoch':n2}\n","opt_list=[opt1,opt2,opt3,opt3,opt3]\n","opt_t1_list=[opt1_t1,opt2_t1,opt3_t1,opt3_t1,opt3_t1]\n","opt_t0_list=[opt1_t0,opt2_t0,opt3_t0,opt3_t0,opt3_t0]"],"metadata":{"id":"lb26RxcbEgVJ","executionInfo":{"status":"ok","timestamp":1646685338841,"user_tz":300,"elapsed":256,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["\n","# use one feature ver to test \n","# (p,k_split,transOpt) p participant number 1~8\n","# k_split, one \n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","\n","def main_trans_CV1(p_test,k_split,transOpt,FeatOpt,ExpVer):  \n","\n","    \n","\n","       \n","\n","    # ExpVer_list=['2_24']  # trans to small variation in sensor position \n","    # ExpVer_list=['2_1','2_16','2_19'] # sensor position vaiation\n","    file_name_data=r\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"+ExpVer+\"/data_all_multi6_filt_0.1_5.npz\"\n","    data=np.load(file_name_data)\n","    feature_2d_stft=data['feature_2d_stft']\n","    feature_2d_stft2=data['feature_2d_stft2']\n","    feature_2d_cwt=data['feature_2d_cwt']\n","    feature_2d_cwt2=data['feature_2d_cwt2']\n","    feature_2d_cwt3=data['feature_2d_cwt3']\n","\n","    label_all=data['label_all']\n","    caseNum_all=data['caseNum_all']\n","    channel=np.linspace(0,47,48).astype(int) \n","    in_ch=48\n","    num_class=23\n","   \n","    cm=[]\n","    cm_norm=[]\n","    test_y_pred=[]\n","    test_y_true=[]\n","    acc=[]\n","    acc_all=[]\n","    trn_ind=[]\n","    tst_ind=[]\n","\n","    feature_list=[feature_2d_stft,feature_2d_stft2[:,:,:40,:40],feature_2d_cwt,feature_2d_cwt2,feature_2d_cwt3]\n","    feature_listName=[\"stft\",\"stft2\",\"cwt\",\"cwt2\",\"cwt3\"]\n","    if __name__ == '__main__':\n","      \n","        l=FeatOpt  # feature list index. \"stft\",\"stft2\",\"cwt\",\"cwt2\",\"cwt3\"\n","  \n","    \n","\n","       # k_split=3 # k-fold  1/n train \n","       # n_sel=0 \n","\n","        #model_trans=Load_TransModel(l,p_test,opt_list[l]) #  (FeatType,person,opt):     FeatType: ['stft','stft2','cwt','cwt2','cwt3'] \n","\n","        for j in range(k_split):\n","          if transOpt==1:\n","            opt_temp=opt_t1_list[l]\n","          if transOpt==0:\n","            opt_temp=opt_t0_list[l]\n","          opt_temp_arr=np.array(list(opt_temp.items()));\n","\n","          model_trans=Load_TransModel(l,p_test,opt_list[l])\n","          cm_temp,acc_temp,test_y_temp,trn_ind_temp,tst_ind_temp=test_trans(feature_list[l][:,channel,:,:],label_all[:],opt_temp,k_split,j,model_trans)\n","  \n","    \n","          cm.append(cm_temp)\n","          acc_all.append(acc_temp)\n","          \n","          trn_ind.append(trn_ind_temp)\n","          tst_ind.append(tst_ind_temp)\n","\n","      \n","\n","          for k in range(len(tst_ind_temp)):\n","            test_y_pred.append(test_y_temp[1,k])\n","            test_y_true.append(test_y_temp[0,k])\n","  \n","        acc_all=np.array(acc_all)\n","        test_y_pred=np.array(test_y_pred)\n","        test_y_true=np.array(test_y_true)\n","        cm=confusion_matrix(test_y_pred, test_y_true)\n","        cm_norm=confusion_matrix(test_y_pred, test_y_true,normalize='true')\n","        acc=accuracy_score(test_y_pred, test_y_true)\n","\n","   \n","    SaveName='ch'+str(in_ch)+'_'+str(k_split)+'fold_'+feature_listName[l]+'_trans_'+str(transOpt)\n","  \n","    print(cm_norm.shape)\n","    print(test_y_pred.shape)\n","    plotfigFullClass(cm_norm,acc,SaveName,ExpVer)\n"," \n","    np.savez_compressed(\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"+ExpVer+\"/result/npyFile/\"+'vit_'+SaveName+\".npz\",\\\n","                    cm_norm=cm_norm,cm=cm,acc=acc,acc_all=acc_all,\\\n","                    test_y=np.stack((test_y_pred, test_y_true)),test_ind=np.array(tst_ind),\\\n","                   parameter_vit=parameter_vit,opt=opt_temp_arr)\n","    \n","# main_trans_CV1(p_test,k_split,transOpt,FeatOpt)  \n","\n","\n","p_test=2 # general mode choose exc_#  not important differnece\n","\n","ExpVer_list=['2_1','2_16','2_19'] # sensor position vaiation\n","for i in range(len(ExpVer_list)):\n","  for vv in range(5): # feat version 0~4\n","    for k in [4,5]:\n","      main_trans_CV1(p_test,k,1,vv,ExpVer_list[i])\n","    \n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5d52ceac-cde3-49ae-9835-4b8ecbd7959f","id":"_VLIZtHnEkPd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","[[59  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n"," [ 0 32  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  3 31  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 21  5  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 25  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  1  4 18  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  3  0 20  3  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n"," [ 0  0  0  1  0  0  0  1 23  0  0  0  0  0  0  0  0  0  2  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 22  4  0  0  0  0  0  0  0  0  0  1  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  0 26  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 19  1  0  0  0  2  0  0  0  0  2  3]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  2  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  1  0  0  0  0  0  1  0  1 22  0  0  0  0  1  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 26  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 26  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0 27  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0]\n"," [ 0  2  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  1  0 22  2  0  0]\n"," [ 0  1  3  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  6 19  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0 28  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2 28]] 0.8810572687224669\n","[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 31  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n"," [ 0  2 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0]\n"," [ 0  0  0 26  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0 19  4  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  1  0  0  0  3 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0 23  2  1  0  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  3 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  1  0  0  0  0  0  0  0 21  2  0  0  0  0  0  0  1  0  2  0  0  0]\n"," [ 0  0  1  0  0  0  0  0  0  3 22  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 20  3  0  0  0  3  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0 22  2  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1 26  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  1  0 25  2  0  0  0  0]\n"," [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1 28  0  0  0  0]\n"," [ 0  2  2  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0 21  1  0  1]\n"," [ 0  0  3  0  0  0  0  0  4  0  0  0  0  0  0  0  0  0  0  1 22  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  1  0  0  0  0  0 27  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  2  1  0  0  0  0  0  2 24]] 0.8795888399412628\n","[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  2 26  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  3  0  1  0  0]\n"," [ 1  0  0 22  1  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0 25  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 23  2  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  1  5 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0  0  0 15  2  0  0  0  0  0  0  0  0  4  0  2  3  0  0]\n"," [ 0  0  0  0  0  0  2  0 21  0  0  0  0  0  0  0  0  2  1  1  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 24  3  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  2 25  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  1  0  0  0  0  0  0  0  0 22  1  0  0  0  2  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0 24  1  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0]\n"," [ 0  1  1  0  1  0  0  0  1  0  0  0  0  0  0  0  0 24  0  0  0  0  0]\n"," [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0]\n"," [ 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0 25  3  0  1]\n"," [ 0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  5 22  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0 23  4]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  3  1  0  0  0  0  1 24]] 0.8707782672540382\n","[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 30  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  6 26  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 23  3  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0 26  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 24  1  1  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n"," [ 0  2  0  0  0  4 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  1  0  0  0  2  0 16  6  0  0  0  0  0  0  0  0  1  0  1  0  0  0]\n"," [ 0  0  1  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  3  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 21  6  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 23  1  0  0  0  1  0  0  0  0  0  2]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0]\n"," [ 3  0  0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 26  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0 18  7  0  0  1  0]\n"," [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29  1  0  0]\n"," [ 0  0  3  0  0  0  0  0  0  1  2  0  0  0  0  0  0  0  0  4 20  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  2  0  0  0  0 25  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  0  0  1 27]] 0.8707782672540382\n","(23, 23)\n","(2724,)\n","[[63  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n"," [ 0 31  1  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  1  0  0  0]\n"," [ 0  4 31  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 17  8  0  3  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  3 23  0  0  1  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 24  4  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  1  4 19  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  3  0 17  8  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  1  0  0  0  1 26  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 23  5  0  1  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  0 27  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  1  0  0  0  0  0  0  0  0 15  1  0  0  0  5  0  0  0  0  2  5]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0 26  1  0  0  0  0  0  0  0  0]\n"," [ 2  0  0  0  0  0  0  0  0  0  0  1  0  1 25  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0 25  0  0  0  0  1  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 28  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  1 30  0  0  0  0]\n"," [ 0  3  0  0  0  2  0  1  0  0  0  1  0  0  0  0  0  0  0 24  1  0  0]\n"," [ 0  1  5  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  9 15  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0 31  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  4 26]] 0.8319559228650137\n","[[63  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 35  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0]\n"," [ 0  3 29  0  0  0  0  0  1  0  2  0  0  0  0  0  0  0  0  0  0  1  0]\n"," [ 0  0  0 24  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  4 25  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 19  3  2  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0]\n"," [ 0  0  0  0  1  2 21  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n"," [ 0  1  0  0  0  1  0 23  2  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  1  0  0  0  0  1 26  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  2  1  0  0  0  0  0  0 24  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  3  0  0  0  0  0  0  1 24  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 13  3  0  0  0 11  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  1  0  0  0  0  0  0  0]\n"," [ 2  0  0  0  0  0  0  0  0  0  0  0  0 23  2  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0  0 27  1  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 27  0  0  0  0  0  1]\n"," [ 0  2  0  0  0  0  0  6  0  0  0  0  0  0  0  1  0 18  3  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 32  0  0  0  0]\n"," [ 0  2  1  0  0  1  2  0  0  0  0  0  0  0  0  0  0  0  0 19  7  0  0]\n"," [ 0  0  2  0  0  0  1  0  3  0  0  0  0  0  0  0  0  0  0  2 24  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0 30  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  6  2  1  0  0  0  0  2 21]] 0.8319559228650137\n","[[64  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 35  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0 31  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  3  0  1  0  0]\n"," [ 0  0  0 19  8  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  8 20  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0 25  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  9 17  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0 24  1  0  0  0  0  0  0  0  0  1  0  1  1  0  0]\n"," [ 0  0  0  1  0  0  1 11 15  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  2  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  4 24  0  0  0  0  0  0  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  4  0  0  0  0  0  2]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  1  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0  0  0  0  0  0  0  0  0 23  4  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  1  0  0  0  0  0  0  0  1 26  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0  0  0  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0]\n"," [ 0  0  0  1  1  0  0  3  0  0  0  0  0  0  0  0  0 23  2  0  0  0  0]\n"," [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  2 29  0  0  0  0]\n"," [ 0  1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0 26  3  0  1]\n"," [ 0  1  0  0  0  0  0  0  1  0  2  0  1  0  0  0  0  0  0  2 25  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  4  0  1  0  1  0  0  0  0  0 26  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  0 30]] 0.8484848484848485\n","[[64  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 30  5  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0]\n"," [ 0  5 26  0  0  0  1  0  0  0  3  0  0  0  0  0  0  0  1  0  1  0  0]\n"," [ 0  0  0 27  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  3 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 22  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  4 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  1  0 18  4  1  0  0  0  0  0  0  0  4  0  1  0  0  0]\n"," [ 0  0  1  0  0  2  0  1 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 20  9  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  3 26  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  1  0  0  0  0  0  0  0  0 24  2  0  0  0  1  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0  0  0  0  0  0  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0 26  1  0  0  0  0  0  0  0  0]\n"," [ 2  0  0  1  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0 26  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 30  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  1 29  0  0  0  0]\n"," [ 0  0  0  0  0  2  0  0  0  0  0  0  1  0  0  0  0  0  0 20  9  0  0]\n"," [ 0  1  1  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  2 26  1  0]\n"," [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  2  0  0  0  0  0 29  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  2  1  0  0  0  0  6 21]] 0.8459422283356258\n","[[64  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 30  6  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 11 24  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 24  2  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1 27  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n"," [ 0  2  0  0  0  7 16  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0]\n"," [ 0  1  0  0  0  3  0 15  8  0  0  0  0  0  0  0  0  1  0  1  0  0  0]\n"," [ 0  1  0  0  0  0  0  2 22  0  0  0  0  0  0  0  0  1  3  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 26  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  5 23  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  2  0  0  0  0  1  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 29  0  0  0  0  0  0  0  0  0  0]\n"," [ 2  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0  1 27  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 28  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0  0  0  0]\n"," [ 0  1  0  2  1  0  0  1  1  0  0  0  0  0  0  1  0 19  5  0  0  0  0]\n"," [ 0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 29  0  0  0  0]\n"," [ 0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0 24  6  0  0]\n"," [ 0  1  4  0  0  0  0  0  0  1  2  0  0  0  0  0  0  0  0  1 23  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  1  1  0  0  0  0 27  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  3  0  0  0  0  1 26]] 0.8349381017881705\n","(23, 23)\n","(3632,)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:90: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"]},{"output_type":"stream","name":"stdout","text":["[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 32  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  1 32  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 21  4  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 24  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  1 23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0 24  2  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 24  3  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  1  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 20  1  0  0  0  3  0  0  0  0  2  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  2  0  0  0  0  0  0  0  0  0  2 23  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0 25  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0 28  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0]\n"," [ 0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 28  0  0  0]\n"," [ 0  1  1  0  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  2 23  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0 28  1]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  2 27]] 0.9236417033773862\n","[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 32  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0 34  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  1  0 23  1  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0 23  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  3 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 24  1  0  0  0  0  0  0  0  0  2  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0 26  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 20  2  0  0  0  4  0  0  0  0  1  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0 22  2  0  0  0  0  0  0  0  0]\n"," [ 2  0  0  1  0  0  0  0  0  0  0  0  0  1 23  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0]\n"," [ 0  2  0  0  0  0  0  2  0  1  0  0  0  0  0  0  0 22  2  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0]\n"," [ 0  3  0  0  0  0  0  2  0  0  0  1  0  0  0  0  0  0  0 22  2  0  0]\n"," [ 0  2  3  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  0 20  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0 28  0]\n"," [ 0  0  0  0  0  0  0  0  0  1  0  0  1  0  1  1  0  0  0  0  0  2 24]] 0.9074889867841409\n","[[60  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0 32  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  1  0  0  0]\n"," [ 0  3 28  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  1  0  0]\n"," [ 0  0  0 21  2  0  3  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n"," [ 0  0  0  0 25  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0 22  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  2 22  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  1  0 20  2  0  0  0  0  0  0  0  0  3  0  1  0  0  0]\n"," [ 0  0  0  0  0  0  0  3 23  0  0  0  0  0  0  0  0  0  1  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0 20  7  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0 23  2  0  0  0  2  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0  0  0  0]\n"," [ 1  0  0  0  0  0  0  0  0  0  0  0  0 24  1  0  0  0  0  0  0  0  0]\n"," [ 3  0  0  0  0  0  0  0  0  0  0  0  0  1 23  0  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1 22  2  3  0  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 30  0  0  0  0]\n"," [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0 25  3  0  0]\n"," [ 0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  5 24  0  0]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0 25  3]\n"," [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  3 25]] 0.8839941262848752\n"]}]},{"cell_type":"code","source":["\n","\n","def plotfigFullClass(cm,acc,tle,ExpVerN):\n","\n","    parent_dir = r\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"+ExpVerN+\"/result/\"\n","    path1 = os.path.join(parent_dir, 'cm_fig')\n","    os.makedirs(path1, exist_ok = True) \n","    path1 = os.path.join(parent_dir, 'npyFile')\n","    os.makedirs(path1, exist_ok = True) \n","\n","    th=0.01\n","\n","    labelNum=str(1)  #labelling method 1,2,3,4\n","    size=15\n","    name1=[\"R\", \"G\",\"G*2\",\"P1\",\"P1*2\",\"P2\",\"P2*2\",\"P23\",\"P23*2\",\"P4\",\"P4*2\",\"sG\",\"sF\",\"sP1\",\"sP2\",\"sP23\",\"sP4\",\"U\",\"U*2\",\"D\",\"D*2\",\"sU\",\"sD\"]\n","    name2=name1\n","    w=20 #fig size 1      change when label num change\n","    h=22   #fig size 2\n","    \n","    # true_num=0\n","    # for i in range (len(cm)):\n","    #   true_num=true_num+ cm[i,i]\n","    # acc=true_num/np.sum(cm)   \n","    \n","    df_cm = pd.DataFrame(cm, index=name1, columns=name2)\n","    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","    plt.figure()\n","    sn.set(font_scale=1.2)\n","    mask = np.zeros_like(df_cm)\n","    mask[np.where(cm<th)] = True\n","    \n","    sn.heatmap(df_cm, cmap=\"YlGnBu\",fmt=\".2f\",vmin=0, vmax=1.0,annot=True,mask=mask,square=True,cbar=False,annot_kws={\"size\": size,'fontsize':15})\n"," \n","    s01=' Acc={n:.3f}'.format(n=acc)\n","    #plt.text(a,b,s01,fontsize=size)\n","    \n","    tleSave='vit_'+tle\n","    plt.title(tle+s01)\n","\n","    figure = plt.gcf()\n","    figure.set_size_inches(w, h)\n","    \n","    plt.savefig(parent_dir+r\"cm_fig/\"+tleSave+\"CM.png\", dpi=300)\n","\n","\n"],"metadata":{"id":"CXlRIaYjoQC_","executionInfo":{"status":"ok","timestamp":1646684577611,"user_tz":300,"elapsed":897,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"execution_count":10,"outputs":[]}]}