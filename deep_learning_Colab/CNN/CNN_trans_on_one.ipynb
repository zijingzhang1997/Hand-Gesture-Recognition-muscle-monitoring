{"cells":[{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6690,"status":"ok","timestamp":1646660138858,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"},"user_tz":300},"id":"ZII5pk69M1cG"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib\n","import torch\n","# !pip install mat73\n","# import mat73\n","import matplotlib.pyplot as plt\n","import csv\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader, random_split,TensorDataset\n","from torchvision import transforms, utils\n","import time\n","import pandas as pd\n","import scipy.io\n","import sklearn.metrics\n","import seaborn as sns\n","import random\n","from sklearn.model_selection import train_test_split\n","from torchvision.transforms import ToTensor\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import accuracy_score\n","random.seed(1)\n","torch.manual_seed(1)\n","torch.cuda.manual_seed(1)\n","np.random.seed(1)\n","\n","from scipy import signal\n","\n","from sklearn.metrics import confusion_matrix\n","\n","import seaborn as sn\n","import pandas as pd\n","\n","from sklearn.model_selection import RepeatedStratifiedKFold\n","from sklearn.model_selection import StratifiedGroupKFold\n","from sklearn.model_selection import LeaveOneGroupOut\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["class Net2_stft(nn.Module):\n","    def __init__(self,in_channels, num_classes):\n","        super(Net2_stft,self).__init__()\n","        n_ch = in_channels  # channel of input \n","        n1 = 200  # This directly affects accuracy if value is low.\n","        n2 = 200\n","        n3 = 100\n","        n4 = 50\n","        n5=50\n","        n_l1=7200\n","        n_l2=200\n","       \n","      \n","        self.conv1 = nn.Conv2d(n_ch, n1, 5)\n","        self.bn1 = nn.BatchNorm2d(n1)\n","        #self.pool1 = nn.MaxPool1d(2)\n","        self.conv2 = nn.Conv2d(n1, n2, 3)\n","        \n","        self.bn2 = nn.BatchNorm2d(n2)\n","        self.conv3 = nn.Conv2d(n2, n3, 2,2)\n","        self.bn3 = nn.BatchNorm2d(n3)\n","        self.conv4 = nn.Conv2d(n3, n4, 2,2)\n","        self.bn4 = nn.BatchNorm2d(n4)\n","        self.fc1 = nn.Linear(n_l1, n_l2)\n","        self.fc2 = nn.Linear(n_l2, num_classes)\n","       \n","\n","\n","    def forward(self, x):\n","      \n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        #x = self.pool1(x)\n","        #print(x.shape)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        #print(x.shape)\n","        x = self.conv3(x)\n","        x = F.relu(self.bn3(x))\n","        #print(x.shape)\n","        x = self.conv4(x)\n","        x = F.relu(self.bn4(x))\n","        # x = self.conv5(x)\n","        # x = F.relu(self.bn5(x))\n","        # x = self.pool1(x)\n","        #print(x.shape)\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        #print(x.shape)\n","        x = F.relu(self.fc1(x))\n","       \n","        x = self.fc2(x)\n","       \n","        \n","        return x\n","\n","class Net2_stft2(nn.Module):\n","    def __init__(self,in_channels, num_classes):\n","        super(Net2_stft2,self).__init__()\n","        n_ch = in_channels  # channel of input \n","        n1 = 200  # This directly affects accuracy if value is low.\n","        n2 = 200\n","        n3 = 100\n","        n4 = 50\n","    \n","        n_l1=3200\n","        n_l2=200\n","       \n","      \n","        self.conv1 = nn.Conv2d(n_ch, n1, 5)\n","        self.bn1 = nn.BatchNorm2d(n1)\n","        #self.pool1 = nn.MaxPool1d(2)\n","        self.conv2 = nn.Conv2d(n1, n2, 3)\n","        \n","        self.bn2 = nn.BatchNorm2d(n2)\n","        self.conv3 = nn.Conv2d(n2, n3, 2,2)\n","        self.bn3 = nn.BatchNorm2d(n3)\n","        self.conv4 = nn.Conv2d(n3, n4, 2,2)\n","        self.bn4 = nn.BatchNorm2d(n4)\n","        self.fc1 = nn.Linear(n_l1, n_l2)\n","        self.fc2 = nn.Linear(n_l2, num_classes)\n","       \n","\n","\n","    def forward(self, x):\n","      \n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        #x = self.pool1(x)\n","        #print(x.shape)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        #print(x.shape)\n","        x = self.conv3(x)\n","        x = F.relu(self.bn3(x))\n","        #print(x.shape)\n","        x = self.conv4(x)\n","        x = F.relu(self.bn4(x))\n","        # x = self.conv5(x)\n","        # x = F.relu(self.bn5(x))\n","        # x = self.pool1(x)\n","        #print(x.shape)\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        #print(x.shape)\n","        x = F.relu(self.fc1(x))\n","       \n","        x = self.fc2(x)\n","       \n","        \n","        return x\n","\n","\n","class Net2_cwt(nn.Module):\n","    def __init__(self,in_channels, num_classes):\n","        super(Net2_cwt,self).__init__()\n","        n_ch = in_channels  # channel of input \n","        n1 = 200  # This directly affects accuracy if value is low.\n","        n2 = 100\n","        n3 = 50\n","        n4 = 50\n","       \n"," \n","        n_l1=4200\n","        n_l2=200\n","       \n","      \n","        self.conv1 = nn.Conv2d(n_ch, n1, (5, 3),2)\n","        self.bn1 = nn.BatchNorm2d(n1)\n","        #self.pool1 = nn.MaxPool1d(2)\n","        self.conv2 = nn.Conv2d(n1, n2, (5, 3),2)\n","        \n","        self.bn2 = nn.BatchNorm2d(n2)\n","        self.conv3 = nn.Conv2d(n2, n3, (5, 2))\n","        self.bn3 = nn.BatchNorm2d(n3)\n","        self.conv4 = nn.Conv2d(n3, n4, (5, 2))\n","        self.bn4 = nn.BatchNorm2d(n4)\n","        # self.conv5 = nn.Conv2d(n4, n5, 2)\n","        # self.bn5 = nn.BatchNorm2d(n5)\n","     \n","        \n","        self.fc1 = nn.Linear(n_l1, n_l2)\n","       \n","   \n","        self.fc2 = nn.Linear(n_l2, num_classes)\n","      \n","        \n","\n","\n","    def forward(self, x):\n","      \n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        #x = self.pool1(x)\n","        #print(x.shape)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        #print(x.shape)\n","        x = self.conv3(x)\n","        x = F.relu(self.bn3(x))\n","        #print(x.shape)\n","        x = self.conv4(x)\n","        x = F.relu(self.bn4(x))\n","        # x = self.conv5(x)\n","        # x = F.relu(self.bn5(x))\n","        # x = self.pool1(x)\n","        #print(x.shape)\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        #print(x.shape)\n","        x = F.relu(self.fc1(x))\n","       \n","        x = self.fc2(x)\n","       \n","        \n","        return x\n","\n","# 1D CNN\n","class Net(nn.Module):\n","    def __init__(self,in_channels, num_classes):\n","        super(Net,self).__init__()\n","        \n","        n1 = 128 # This directly affects accuracy if value is low.\n","        n2 = 128\n","        n3 = 64\n","        n4 = 64\n","        \n","        n_l1=4544\n","        n_l2=200\n","       \n","        n_out =8   # output channel  (classification)\n","        oc = 2\n","        self.conv1 = nn.Conv1d(in_channels, n1, 100, 4)\n","        self.bn1 = nn.BatchNorm1d(n1)\n","        #self.pool1 = nn.MaxPool1d(2)\n","        self.conv2 = nn.Conv1d(n1, n2, 25,2)\n","        self.bn2 = nn.BatchNorm1d(n2)\n","        self.conv3 = nn.Conv1d(n2, n3, 5,2)\n","        self.bn3 = nn.BatchNorm1d(n3)\n","        self.conv4 = nn.Conv1d(n3, n4, 2,2)\n","        self.bn4 = nn.BatchNorm1d(n4)\n","        # self.conv5 = nn.Conv1d(n4, n5, 2,2)\n","        # self.bn5 = nn.BatchNorm1d(n5)\n","        #self.pool1=nn.AvgPool1d(2)\n","        #self.pool2=nn.MaxPool1d(2)\n","        \n","        self.fc1 = nn.Linear(n_l1, n_l2)\n","        self.fc2 = nn.Linear(n_l2, num_classes)\n","        \n","\n","\n","    def forward(self, x):\n","    \n","        x = self.conv1(x)\n","        x = F.relu(self.bn1(x))\n","        #x = self.pool1(x)\n","        #print(x.shape)\n","        x = self.conv2(x)\n","        x = F.relu(self.bn2(x))\n","        #print(x.shape)\n","        x = self.conv3(x)\n","        x = F.relu(self.bn3(x))\n","        #print(x.shape)\n","        x = self.conv4(x)\n","        x = F.relu(self.bn4(x))\n","        # x = self.conv5(x)\n","        # x = F.relu(self.bn5(x))\n","        #x = self.pool1(x)\n","        #print(x.shape)\n","        x = torch.flatten(x, 1) # flatten all dimensions except batch\n","        #print(x.shape)\n","        x = F.relu(self.fc1(x))\n","       \n","        x = self.fc2(x)\n","       \n","        \n","        return x"],"metadata":{"id":"oJrYDshhf5-Y","executionInfo":{"status":"ok","timestamp":1646660139091,"user_tz":300,"elapsed":235,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1646660139427,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"},"user_tz":300},"id":"VgrJAtXbYyoc"},"outputs":[],"source":["def Load_TransModel(FeatType,person):\n","\n","  dataPath=\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"\n","  FeatName=['stft','stft2','cwt','cwt2','cwt3']\n","  NetType=[Net2_stft,Net2_stft2,Net2_cwt,Net2_cwt,Net2_cwt,Net] \n","  PATH=dataPath+\"/model_all_CNN/\"+FeatName[FeatType]+\"_ex_\"+str(person)+\".pt\"\n","  model_trans = NetType[FeatType](in_ch, num_class)\n","  model_trans.load_state_dict(torch.load(PATH))\n","  model_trans.eval()\n","\n","\n","  return model_trans\n","\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"hv19s1FdufVK","executionInfo":{"status":"ok","timestamp":1646660139427,"user_tz":300,"elapsed":2,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"outputs":[],"source":["in_ch=48\n","num_class=23\n","\n","\n","\n","def test_trans(X_all,y_all,opt,k_split,n_sel,trans_net):\n","  import torch\n","  torch.cuda.empty_cache()\n","\n","  if __name__ == '__main__':\n","      \n","      transform = ToTensor()\n","      batchsize_train = 16\n","\n","      folds=RepeatedStratifiedKFold(n_splits=k_split, n_repeats=1,random_state=100).split(X_all,y_all)\n","\n","      test_ind_all=[]\n","      train_ind_all=[]\n","      for train_index, test_index in folds:\n","        test_ind_all.append(test_index)\n","        train_ind_all.append(train_index)\n","      \n","\n","      # train_ind=train_ind_all[n_sel]\n","      # test_ind=test_ind_all[n_sel]\n","\n","      # swap train & test index \n","      # select one fold to be trained by n_sel\n","      train_ind=test_ind_all[n_sel]\n","      test_ind=train_ind_all[n_sel]\n","\n","\n","      X_train=X_all[train_ind] \n","      X_test=X_all[test_ind]\n","      y_train=y_all[train_ind] \n","      y_test=y_all[test_ind]\n","\n","      train_loader = DataLoader(TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train)), batch_size=batchsize_train,shuffle=True)\n","      batchsize_test = 16\n","      test_loader = DataLoader(TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test)), batch_size=batchsize_test, shuffle=False)\n","\n","\n","      # (unique, counts) = np.unique(perNum_all_per[ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","\n","      # (unique, counts) = np.unique(label_all_per[ind][train_ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","      # (unique, counts) = np.unique(label_all_per[ind][test_ind], return_counts=True)\n","      # frequencies = np.asarray((unique, counts)).T\n","      # print(frequencies)\n","\n","      #hyperparameter definition   \n","      momentum = 0.1\n","      random_seed=1\n","      torch.backends.cudnn.enabled = False\n","      torch.manual_seed(random_seed)     #设定随机数种子为固定值\n","      \n","      train_loss_epoch = []\n","      test_acc_epoch =[]\n","      total_acc_epoch = []\n","      #epoch_range = np.arange(25,225,25)\n","      epoch_range = np.array([2])\n","\n","   \n","      if opt['trans']==0:       \n","              if opt['net']=='stft':\n","                network = Net2_stft(in_ch,num_class).cuda()\n","              if opt['net']=='stft2':\n","                network = Net2_stft2(in_ch,num_class).cuda()\n","              if opt['net']=='cwt':\n","                network = Net2_cwt(in_ch,num_class).cuda()\n","              if opt['net']=='1d':\n","                network = Net(in_ch,num_class).cuda()\n","      if opt['trans']==1:\n","        network =trans_net.cuda()\n","      #training\n","      learning_rate=opt['learning rate']\n","      optimizer = optim.Adam(network.parameters(), lr=learning_rate)\n","      #optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n","      \n","\n","      #network.train()\n","      Training_Loss = []\n","      Test_Loss = []\n","      start_time = time.time()\n","      criterion = nn.CrossEntropyLoss()\n","      #criterion = nn.CrossEntropyLoss(weight=torch.Tensor([1, 3]).cuda())\n","      for epoch in range(opt['n_epoch']):   # loop over the dataset multiple times\n","          train_loss = 0\n","          for X, Y in train_loader:\n","              # X = X.view(-1,1,X.shape[2],X.shape[3]).cuda()\n","              X = X.float().cuda()  \n","              Y = Y.long().view(-1, ).cuda() \n","              current_batchsize = X.shape[0]\n","              optimizer.zero_grad()\n","              output = network(X)\n","              loss = criterion(output,Y)\n","              train_loss = train_loss + loss.item()\n","              loss.backward()                     #calculate the gradient decent\n","              optimizer.step()                    #update the weight\n","              \n","            \n","          test_loss = 0\n","          correct = 0\n","          total = 0\n","          test_y= []\n","          test_y_p = []\n","     \n","          with torch.no_grad():        \n","              # X = X.view(-1,X.shape[1],X.shape[2])\n","              # X = X.float()         \n","              for X, Y in test_loader:\n","                  X = torch.Tensor(X).cuda()\n","                  Y = torch.Tensor(Y).long().view(-1, ).cuda()\n","                  images, labels = X, Y\n","                  # calculate outputs by running images through the network\n","                  outputs = network(images)\n","                  loss = criterion(outputs,Y)\n","                  test_loss = test_loss + loss.item()\n","\n","                  # the class with the highest energy is what we choose as prediction\n","                  _, predicted = torch.max(outputs.data, 1)\n","                  total += labels.size(0)\n","                  correct += (predicted == labels).sum().item()\n","                  \n","                  for i in range(len(labels)):\n","                    test_y.append(labels[i])\n","                    test_y_p.append(predicted[i])\n","          \n","          #print('Accuracy of test cases: %d %%' % (100 * correct / total))\n","  \n","\n","          Training_Loss.append(train_loss/len(train_loader.dataset))\n","          Test_Loss.append(test_loss/len(test_loader.dataset))\n","  \n","\n","  test_y_p=torch.FloatTensor(test_y_p)\n","  test_y=torch.FloatTensor(test_y)\n","  test_y_p=np.array(test_y_p.cpu())\n","  test_y=np.array(test_y.cpu())\n","  test_y2=np.stack((test_y, test_y_p))\n","  \n","  train_ind_inAll=train_ind\n","  test_ind_inAll=test_ind\n","\n","  trn_tst_ind=[train_ind_inAll,test_ind_inAll]\n","\n","  cm=confusion_matrix(test_y, test_y_p)\n","  acc=accuracy_score(test_y, test_y_p)\n","  print(cm,acc)\n","  return cm,acc,test_y2,train_ind_inAll,test_ind_inAll\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"id":"CXlRIaYjoQC_","executionInfo":{"status":"ok","timestamp":1646670707789,"user_tz":300,"elapsed":213,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"outputs":[],"source":["Folder='model_all_CNN/trans_result/'\n","\n","def plotfigFullClass(cm,acc,tle,per):\n","\n","    parent_dir = r\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"+Folder+str(per)+'/'\n","    path1 = os.path.join(parent_dir, 'cm_fig')\n","    os.makedirs(path1, exist_ok = True) \n","    path1 = os.path.join(parent_dir, 'npyFile')\n","    os.makedirs(path1, exist_ok = True) \n","    \n","\n","    name1=[\"R\", \"G\",\"G*2\",\"P1\",\"P1*2\",\"P2\",\"P2*2\",\"P23\",\"P23*2\",\"P4\",\"P4*2\",\"sG\",\"sF\",\"sP1\",\"sP2\",\"sP23\",\"sP4\",\"U\",\"U*2\",\"D\",\"D*2\",\"sU\",\"sD\"]\n","    name2=name1\n","    w=20 #fig size 1      change when label num change\n","    h=22   #fig size 2\n","    \n","    # true_num=0\n","    # for i in range (len(cm)):\n","    #   true_num=true_num+ cm[i,i]\n","    # acc=true_num/np.sum(cm)   \n","    \n","    df_cm = pd.DataFrame(cm, index=name1, columns=name2)\n","    plt.rcParams[\"font.family\"] = \"Times New Roman\"\n","    plt.figure()\n","    sn.set(font_scale=1.2)\n","    mask = np.zeros_like(df_cm)\n","    mask[np.where(cm==0)] = True\n","    \n","    sn.heatmap(df_cm, cmap=\"YlGnBu\",fmt=\".2f\",vmin=0, vmax=1.0,annot=True,mask=mask,square=True,cbar=False,annot_kws={\"size\": 15,'fontsize':15})\n"," \n","    s01=' Acc={n:.3f}'.format(n=acc)\n","    #plt.text(a,b,s01,fontsize=size)\n","    \n","    tleSave=tle\n","    plt.title(tle+s01)\n","\n","    figure = plt.gcf()\n","    figure.set_size_inches(w, h)\n","    \n","    plt.savefig(parent_dir+r\"cm_fig/\"+tleSave+\"CM.png\", dpi=300)\n","\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"DYciIcz7MDgu","executionInfo":{"status":"ok","timestamp":1646663709630,"user_tz":300,"elapsed":241,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"outputs":[],"source":["\n","\n","## for testing kfold CV transfer option\n","n1=30\n","#lr1=1e-5 #  old version. accuracy is lower for participants with higher accuracy, more similarity \n","lr1=5e-5  # for participant except 1 \n","#lr1=2e-4  # for participant 1 \n","opt1_t1={'net':'stft','trans':1,'learning rate':lr1,'n_epoch':n1}\n","opt2_t1={'net':'stft2','trans':1,'learning rate':lr1,'n_epoch':n1}\n","opt3_t1={'net':'cwt','trans':1,'learning rate':lr1,'n_epoch':n1}\n","## for testing kfold CV not transfer option\n","n2=25\n","opt1_t0={'net':'stft','trans':0,'learning rate':2e-4,'n_epoch':n2}\n","opt2_t0={'net':'stft2','trans':0,'learning rate':2e-4,'n_epoch':n2}\n","opt3_t0={'net':'cwt','trans':0,'learning rate':2e-4,'n_epoch':n2}\n","\n","opt_t1_list=[opt1_t1,opt2_t1,opt3_t1,opt3_t1,opt3_t1]\n","opt_t0_list=[opt1_t0,opt2_t0,opt3_t0,opt3_t0,opt3_t0]"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","FiltName='filt_0.1_5'\n","file_name_data=r\"/content/drive/My Drive/Colab Notebooks/RFMG/data/data_all_per8_multi6_filt_0.1_5.npz\"\n","data=np.load(file_name_data)\n","\n","feature_stft_per=data['feature_stft_per']\n","feature_stft2_per=data['feature_stft2_per']\n","\n","feature_cwt_per=data['feature_cwt_per']\n","feature_cwt2_per=data['feature_cwt2_per']\n","feature_cwt3_per=data['feature_cwt3_per']\n","\n","label_all_per=data['label_all_per']\n","caseNum_all_per=data['caseNum_all_per']\n","perNum_all_per=data['perNum_all_per']\n","\n","data=[]"],"metadata":{"id":"KCM49z9vWKW_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646663697016,"user_tz":300,"elapsed":69157,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}},"outputId":"c7e0c92e-eee6-46e9-c099-81160ea7ee9c"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1Vg0oT5nERY7ns-_7TxkQlgIM93BjEZD8"},"id":"H1Qy15WGQFlr","outputId":"28a3dec5-e432-4ef7-ccfc-bb86dc806bf1","executionInfo":{"status":"ok","timestamp":1646675974127,"user_tz":300,"elapsed":5251075,"user":{"displayName":"Zijing Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhOGqelSoQ8DBz00Gsbqr9QBAymTf0Nlug7AzpX=s64","userId":"03111893666314698246"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["\n","# use one feature ver to test \n","# (p,k_split,transOpt) p participant number 1~8\n","# k_split, one \n","feature_list=[feature_stft_per,feature_stft2_per,feature_cwt_per,feature_cwt2_per,feature_cwt3_per]\n","def main_trans_CV1(p,k_split,transOpt,FeatOpt):  \n","\n","    \n","\n","\n","    channel=np.linspace(0,47,48).astype(int) \n","    in_ch=48\n","    num_class=23\n","   \n","    cm=[]\n","    cm_norm=[]\n","    test_y_pred=[]\n","    test_y_true=[]\n","    acc=[]\n","    acc_all=[]\n","    trn_ind=[]\n","    tst_ind=[]\n","\n","    \n","    feature_listName=[\"stft\",\"stft2\",\"cwt\",\"cwt2\",\"cwt3\"]\n","    if __name__ == '__main__':\n","      \n","        l=FeatOpt  # feature list index. \"stft\",\"stft2\",\"cwt\",\"cwt2\",\"cwt3\"\n","  \n","        p_test=p  # test participant's number \n","\n","       # k_split=3 # k-fold  1/n train \n","       # n_sel=0 \n","\n","        ind=np.where(perNum_all_per==p_test)[0]   # participant index for whole kulti dataset \n","        #model_trans=Load_TransModel(l,p_test,opt_list[l]) #  (FeatType,person,opt):     FeatType: ['stft','stft2','cwt','cwt2','cwt3'] \n","\n","        for j in range(k_split):\n","          if transOpt==1:\n","            opt_temp=opt_t1_list[l]\n","          if transOpt==0:\n","            opt_temp=opt_t0_list[l]\n","          opt_temp_arr=np.array(list(opt_temp.items()));\n","\n","          model_trans=Load_TransModel(l,p_test)\n","          \n","          cm_temp,acc_temp,test_y_temp,trn_ind_temp,tst_ind_temp=test_trans(feature_list[l][ind,:,:,:],label_all_per[ind],opt_temp,k_split,j,model_trans)\n","  \n","    \n","          cm.append(cm_temp)\n","          acc_all.append(acc_temp)\n","          \n","          trn_ind.append(trn_ind_temp)\n","          tst_ind.append(tst_ind_temp)\n","\n","      \n","\n","          for k in range(len(tst_ind_temp)):\n","            test_y_pred.append(test_y_temp[1,k])\n","            test_y_true.append(test_y_temp[0,k])\n","  \n","        acc_all=np.array(acc_all)\n","        test_y_pred=np.array(test_y_pred)\n","        test_y_true=np.array(test_y_true)\n","        cm=confusion_matrix(test_y_pred, test_y_true)\n","        cm_norm=confusion_matrix(test_y_pred, test_y_true,normalize='true')\n","        acc=accuracy_score(test_y_pred, test_y_true)\n","\n","   \n","    SaveName='ch'+str(in_ch)+'_'+str(k_split)+'fold_'+feature_listName[l]+'_trans_'+str(transOpt)\n","  \n","    print(cm_norm.shape)\n","    print(test_y_pred.shape)\n","    plotfigFullClass(cm_norm,acc,SaveName,p)\n"," \n","    np.savez_compressed(\"/content/drive/My Drive/Colab Notebooks/RFMG/data/\"+Folder+str(p)+\"/npyFile/\"+SaveName+\".npz\",\\\n","                    cm_norm=cm_norm,cm=cm,acc=acc,acc_all=acc_all,\\\n","                    test_y=np.stack((test_y_pred, test_y_true)),test_ind=np.array(tst_ind)\\\n","                  )\n","    \n","# main_trans_CV1(p,k_split,transOpt,FeatOpt)   \n","\n","# for pp in range(1,9):\n","#   main_trans_CV1(pp,4,1,3)\n","#   main_trans_CV1(pp,4,0,3)\n","# for pp in range(1,9):\n","#   main_trans_CV1(pp,3,1,3)\n","#   main_trans_CV1(pp,3,0,3)\n","for vv in range(5): # feat version 0~4\n","  for pp in range(1,9): # participant number label 1~8 \n","    for k in [4,5]:\n","    \n","      main_trans_CV1(pp,k,1,vv)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AJvvcHghZJ0b"},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"machine_shape":"hm","name":"CNN_trans_on_one.ipynb","provenance":[],"mount_file_id":"1N-LIvJ5D4lFt97m2k6A6XDSYKsvEr3Hn","authorship_tag":"ABX9TyOy30aXalQvp4Zk/Wevxtx9"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}